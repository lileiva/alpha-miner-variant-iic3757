{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(string):\n",
    "    case, event = string.replace(\"\\n\",\"\").split(\",\")\n",
    "    return case, event\n",
    "\n",
    "# returns a set with all the activities present in the log\n",
    "# and a dictionary with each event's trace of events\n",
    "# where the key of the dict is the caseId and the value\n",
    "# is an array of events\n",
    "def process_logs(filename):\n",
    "    logs = defaultdict(list)\n",
    "    events = set()\n",
    "    with open(filename, \"r\") as logfile:\n",
    "        for i in logfile.readlines()[1:]:\n",
    "            case, event = formatter(i)\n",
    "            logs[case].append(event)\n",
    "            events.add(event)\n",
    "    return events, logs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a matrix filled with zeros\n",
    "# with dimension equal to the event_set squared.\n",
    "def zero_transition_matrix(event_set):\n",
    "    event_list = list(event_set)\n",
    "    event_list.sort()\n",
    "    event_indexes = {event: index for index, event in enumerate(event_list)}\n",
    "    event_count = len(event_list)\n",
    "    matrix = [[0] * event_count for i in range(event_count)]\n",
    "    return event_indexes, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: D -> 250\n",
      "A: E -> 261\n",
      "A: F -> 261\n",
      "A: G -> 228\n",
      "B: B -> 499\n",
      "B: M -> 268\n",
      "B: P -> 243\n",
      "C: H -> 131\n",
      "C: I -> 130\n",
      "C: K -> 104\n",
      "C: L -> 124\n",
      "D: D -> 249\n",
      "D: E -> 250\n",
      "E: M -> 243\n",
      "E: P -> 268\n",
      "F: H -> 130\n",
      "F: I -> 131\n",
      "G: L -> 104\n",
      "H: J -> 131\n",
      "H: L -> 130\n",
      "I: J -> 130\n",
      "I: L -> 131\n",
      "M: N -> 268\n",
      "M: O -> 243\n",
      "N: Q -> 511\n",
      "O: L -> 511\n",
      "P: N -> 243\n",
      "P: O -> 268\n"
     ]
    }
   ],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "event_indexes, transition_matrix = zero_transition_matrix(events)\n",
    "def generate_succession_matrix(events, logs, window=1):\n",
    "    event_indexes, transition_matrix = zero_transition_matrix(events)\n",
    "    for log in logs.values():\n",
    "        last_checkable_index = len(log) - window\n",
    "        for index in range(0, last_checkable_index):\n",
    "            predecessor = log[index]\n",
    "            successor = log[index + window]\n",
    "            predecessor_index = event_indexes[predecessor]\n",
    "            successor_index = event_indexes[successor]\n",
    "            transition_matrix[predecessor_index][successor_index] += 1\n",
    "    return transition_matrix\n",
    "\n",
    "succession_matrix = generate_succession_matrix(events, logs,2)\n",
    "for letter, index in event_indexes.items():\n",
    "    for letter2, index2 in event_indexes.items():\n",
    "        count = succession_matrix[index][index2]\n",
    "        if count > 0:\n",
    "            print(\"{}: {} -> {}\".format(letter, letter2, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: B -> 0.998\n",
      "A: C -> 0.998\n",
      "B: E -> 0.998\n",
      "C: F -> 0.996\n",
      "C: G -> 0.996\n",
      "E: M -> 0.996\n",
      "E: P -> 0.996\n",
      "F: H -> 0.992\n",
      "F: I -> 0.992\n",
      "G: K -> 0.99\n",
      "G: L -> 0.992\n",
      "H: I -> 0.004\n",
      "H: J -> 0.992\n",
      "I: J -> 0.992\n",
      "J: L -> 0.996\n",
      "K: L -> 0.99\n",
      "M: N -> 0.996\n",
      "M: P -> 0.049\n",
      "N: O -> 0.998\n",
      "O: Q -> 0.998\n",
      "P: N -> 0.996\n",
      "Q: L -> 0.998\n"
     ]
    }
   ],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "def generate_dependancy_matrix(events, logs):\n",
    "    succession_matrix = generate_succession_matrix(events, logs, 1)\n",
    "    event_indexes, dependancy_matrix = zero_transition_matrix(events)\n",
    "    dimension = len(succession_matrix)\n",
    "    for row in range(dimension):\n",
    "        for col in range(dimension):\n",
    "            direct_succession = succession_matrix[row][col]\n",
    "            inverse_succession = succession_matrix[col][row]\n",
    "            if row == col:\n",
    "                dependancy_matrix[row][col] = round((direct_succession / (direct_succession + 1)), 3)\n",
    "            else:\n",
    "                dependancy_matrix[row][col] = round((direct_succession - inverse_succession) / (direct_succession + inverse_succession + 1), 3)\n",
    "    return dependancy_matrix\n",
    "dependancy_matrix = generate_dependancy_matrix(events, logs)\n",
    "for letter, index in event_indexes.items():\n",
    "    for letter2, index2 in event_indexes.items():\n",
    "        count = dependancy_matrix[index][index2]\n",
    "        if count > 0:\n",
    "            print(\"{}: {} -> {}\".format(letter, letter2, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def indexes_to_events(dictionary, transform):\n",
    "    inverse = { v: k for k, v in transform.items() }\n",
    "    result = {}\n",
    "    for key, array in dictionary.items():\n",
    "        letter = inverse[key]\n",
    "        letter_array = [inverse[item] for item in array]\n",
    "        result[letter] = letter_array\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_above_thresholds(frecuency, dependancy, thresholds):\n",
    "    return (frecuency > thresholds[\"frecuency\"] and dependancy > thresholds[\"dependancy\"])\n",
    "\n",
    "def is_below_thresholds(frecuency, dependancy, thresholds):\n",
    "    return (frecuency <= thresholds[\"frecuency\"] and dependancy <= thresholds[\"dependancy\"])\n",
    "\n",
    "def is_above_frecuency_below_dependancy(frecuency, dependancy, thresholds):\n",
    "    return (frecuency > thresholds[\"frecuency\"] and dependancy <= thresholds[\"dependancy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges_above_threshold(edges, thresholds, succession_matrix, dependancy_matrix):\n",
    "    conditions = {}\n",
    "    for start, end in edges:\n",
    "        frecuency = succession_matrix[start][end]\n",
    "        dependancy = dependancy_matrix[start][end]\n",
    "        conditions[(start, end)] = is_above_thresholds(frecuency, dependancy, thresholds)\n",
    "    return conditions\n",
    "\n",
    "def edges_below_threshold(edges, thresholds, succession_matrix, dependancy_matrix):\n",
    "    conditions = {}\n",
    "    for start, end in edges:\n",
    "        frecuency = succession_matrix[start][end]\n",
    "        dependancy = dependancy_matrix[start][end]\n",
    "        conditions[(start, end)] = is_below_thresholds(frecuency, dependancy, thresholds)\n",
    "    return conditions\n",
    "\n",
    "def edges_above_frecuency_below_dependancy(edges, thresholds, succession_matrix, dependancy_matrix):\n",
    "    conditions = {}\n",
    "    for start, end in edges:\n",
    "        frecuency = succession_matrix[start][end]\n",
    "        dependancy = dependancy_matrix[start][end]\n",
    "        conditions[(start, end)] = is_above_frecuency_below_dependancy(frecuency, dependancy, thresholds)\n",
    "    return conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_xor_splits(event_indexes, succession_matrix, dependancy_matrix, thresholds):\n",
    "    xor_nodes = defaultdict(list)\n",
    "    for row in event_indexes.values():\n",
    "        xor_edges = []\n",
    "        for col in event_indexes.values():\n",
    "            xor_edges.append([row, col])\n",
    "        above_threshold = edges_above_threshold(xor_edges, thresholds, succession_matrix, dependancy_matrix)\n",
    "        for edge, above in above_threshold.items():\n",
    "            if above:\n",
    "                xor_nodes[edge[0]].append(edge[1])\n",
    "    xor_nodes = { k: v for k, v in xor_nodes.items() if len(v) > 1 }\n",
    "    print(\"Potential XOR splits (format -> 'start: [ends]'): {}\".format(indexes_to_events(xor_nodes, event_indexes)))    \n",
    "    xor_filtered_nodes = xor_nodes.copy()\n",
    "    for start_node, successors in xor_nodes.items():\n",
    "        edges = []\n",
    "        others = [start_node] + successors        \n",
    "        for successor in successors:\n",
    "            for other in others:\n",
    "                if successor == other:\n",
    "                    continue\n",
    "                edges.append([successor, other])\n",
    "        below_threshold = edges_below_threshold(edges, thresholds, succession_matrix, dependancy_matrix)                \n",
    "        if not all(condition for condition in below_threshold.values()):\n",
    "            xor_filtered_nodes.pop(start_node, None)\n",
    "    print(\"Discovered XOR splits: {}\".format(indexes_to_events(xor_filtered_nodes, event_indexes)))\n",
    "    return xor_filtered_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_xor_joins(event_indexes, succession_matrix, dependancy_matrix, thresholds):\n",
    "    xor_nodes = defaultdict(list)\n",
    "    for current_node in event_indexes.values():\n",
    "        xor_edges = []\n",
    "        for other_node in event_indexes.values():\n",
    "            xor_edges.append([other_node, current_node])\n",
    "        above_threshold = edges_above_threshold(xor_edges, thresholds, succession_matrix, dependancy_matrix)\n",
    "        for edge, above in above_threshold.items():\n",
    "            if above:\n",
    "                xor_nodes[current_node].append(edge[0])\n",
    "    xor_nodes = { k: v for k, v in xor_nodes.items() if len(v) > 1 }\n",
    "    print(\"Potential XOR joins (format -> 'end: [starts]'): {}\".format(indexes_to_events(xor_nodes, event_indexes)))\n",
    "    xor_filtered_nodes = xor_nodes.copy()\n",
    "    for end_node, predecessors in xor_nodes.items():\n",
    "        edges = []\n",
    "        others = [end_node] + predecessors\n",
    "        for predecessor in predecessors:\n",
    "            for other in others:\n",
    "                if predecessor == other:\n",
    "                    continue\n",
    "                edges.append([other, predecessor])\n",
    "        below_threshold = edges_below_threshold(edges, thresholds, succession_matrix, dependancy_matrix)\n",
    "        if not all(condition for condition in below_threshold.values()):\n",
    "            xor_filtered_nodes.pop(end_node, None)\n",
    "\n",
    "    print(\"Discovered XOR joins: {}\".format(indexes_to_events(xor_filtered_nodes, event_indexes)))            \n",
    "    return xor_filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "event_indexes, zero_matrix = zero_transition_matrix(events)\n",
    "succession_matrix = generate_succession_matrix(events, logs)\n",
    "dependancy_matrix = generate_dependancy_matrix(events, logs)\n",
    "\n",
    "def find_and_splits(event_indexes, succession_matrix, dependancy_matrix, thresholds):\n",
    "    and_nodes = defaultdict(list)\n",
    "    for row in event_indexes.values():\n",
    "        and_edges = []\n",
    "        for col in event_indexes.values():\n",
    "            and_edges.append([row, col])\n",
    "        above_threshold = edges_above_threshold(and_edges, thresholds, succession_matrix, dependancy_matrix)\n",
    "        for edge, above in above_threshold.items():\n",
    "            if above:\n",
    "                and_nodes[edge[0]].append(edge[1])\n",
    "    and_nodes = { k: v for k, v in and_nodes.items() if len(v) > 1 }\n",
    "    print(\"Potential AND splits (format -> 'start: [ends]'): {}\".format(indexes_to_events(and_nodes, event_indexes)))    \n",
    "    and_filtered_nodes = and_nodes.copy()\n",
    "    frecuency_thresholds = thresholds.copy()\n",
    "    frecuency_thresholds['dependancy'] = -100000000\n",
    "    for start_node, successors in and_nodes.items():\n",
    "        parallel_edges = []\n",
    "        wrong_edges = []\n",
    "        conditions = {}\n",
    "        others = [start_node] + successors        \n",
    "        for successor in successors:\n",
    "            for other in others:\n",
    "                if successor == other:\n",
    "                    continue\n",
    "                elif other in successors:\n",
    "                    parallel_edges.append([successor, other])\n",
    "                else:\n",
    "                    wrong_edges.append([successor, other])\n",
    "        above_frecuency_threshold = edges_above_frecuency_below_dependancy(parallel_edges, thresholds, succession_matrix, dependancy_matrix)                \n",
    "        below_threshold = edges_above_threshold(wrong_edges, thresholds, succession_matrix, dependancy_matrix)                        \n",
    "        if not all(condition for condition in below_threshold.values()):\n",
    "            and_filtered_nodes.pop(start_node, None)\n",
    "        if not all(condition for condition in above_frecuency_threshold.values()):\n",
    "            and_filtered_nodes.pop(start_node, None)\n",
    "    print(\"Discovered AND splits: {}\".format(indexes_to_events(and_filtered_nodes, event_indexes)))\n",
    "    return and_filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "event_indexes, zero_matrix = zero_transition_matrix(events)\n",
    "succession_matrix = generate_succession_matrix(events, logs)\n",
    "dependancy_matrix = generate_dependancy_matrix(events, logs)\n",
    "\n",
    "def find_and_joins(event_indexes, succession_matrix, dependancy_matrix, thresholds):\n",
    "    and_nodes = defaultdict(list)\n",
    "    for current_node in event_indexes.values():\n",
    "        and_edges = []\n",
    "        for other_node in event_indexes.values():\n",
    "            and_edges.append([other_node, current_node])\n",
    "        above_threshold = edges_above_threshold(and_edges, thresholds, succession_matrix, dependancy_matrix)\n",
    "        for edge, above in above_threshold.items():\n",
    "            if above:\n",
    "                and_nodes[current_node].append(edge[0])\n",
    "    and_nodes = { k: v for k, v in and_nodes.items() if len(v) > 1 }\n",
    "    print(\"Potential AND joins (format -> 'end: [starts]'): {}\".format(indexes_to_events(and_nodes, event_indexes)))\n",
    "    and_filtered_nodes = and_nodes.copy()\n",
    "    for end_node, predecessors in and_nodes.items():\n",
    "        parallel_edges = []\n",
    "        wrong_edges = []\n",
    "        conditions = {}\n",
    "        others = [end_node] + predecessors        \n",
    "        for predecessor in predecessors:\n",
    "            for other in others:\n",
    "                if predecessor == other:\n",
    "                    continue\n",
    "                elif other in predecessors:\n",
    "                    parallel_edges.append([other, predecessor])\n",
    "                else:\n",
    "                    wrong_edges.append([other, predecessor])\n",
    "        above_frecuency_threshold = edges_above_frecuency_below_dependancy(parallel_edges, thresholds, succession_matrix, dependancy_matrix)                \n",
    "        below_threshold = edges_below_threshold(wrong_edges, thresholds, succession_matrix, dependancy_matrix)                        \n",
    "        if not all(condition for condition in below_threshold.values()):\n",
    "            and_filtered_nodes.pop(end_node, None)\n",
    "        if not all(condition for condition in above_frecuency_threshold.values()):\n",
    "            and_filtered_nodes.pop(end_node, None)\n",
    "    print(\"Discovered AND joins: {}\".format(indexes_to_events(and_filtered_nodes, event_indexes)))\n",
    "    return and_filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds setted at:\n",
      "\t* Frecuency: 100\n",
      "\t* Dependancy: 0.2\n",
      "\n",
      "Potential XOR splits (format -> 'start: [ends]'): {'A': ['B', 'C'], 'C': ['F', 'G'], 'E': ['M', 'P'], 'F': ['H', 'I'], 'G': ['K', 'L']}\n",
      "Discovered XOR splits: {'A': ['B', 'C'], 'C': ['F', 'G']}\n",
      "Potential XOR joins (format -> 'end: [starts]'): {'J': ['H', 'I'], 'L': ['G', 'J', 'K', 'Q'], 'N': ['M', 'P']}\n",
      "Discovered XOR joins: {}\n",
      "Potential AND splits (format -> 'start: [ends]'): {'A': ['B', 'C'], 'C': ['F', 'G'], 'E': ['M', 'P'], 'F': ['H', 'I'], 'G': ['K', 'L']}\n",
      "Discovered AND splits: {}\n",
      "Potential AND joins (format -> 'end: [starts]'): {'J': ['H', 'I'], 'L': ['G', 'J', 'K', 'Q'], 'N': ['M', 'P']}\n",
      "Discovered AND joins: {'J': ['H', 'I'], 'N': ['M', 'P']}\n"
     ]
    }
   ],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "event_indexes, zero_matrix = zero_transition_matrix(events)\n",
    "succession_matrix = generate_succession_matrix(events, logs)\n",
    "dependancy_matrix = generate_dependancy_matrix(events, logs)\n",
    "\n",
    "# Setted based on observation\n",
    "thresholds = {\"frecuency\": 100, \"dependancy\": 0.2}  \n",
    "print(\"Thresholds setted at:\\n\\t* Frecuency: {}\\n\\t* Dependancy: {}\\n\".format(thresholds['frecuency'], thresholds['dependancy']))\n",
    "\n",
    "xor_split_nodes = find_xor_splits(event_indexes, succession_matrix, dependancy_matrix, thresholds)\n",
    "xor_join_nodes = find_xor_joins(event_indexes, succession_matrix, dependancy_matrix, thresholds)\n",
    "and_split_nodes = find_and_splits(event_indexes, succession_matrix, dependancy_matrix, thresholds)\n",
    "and_join_nodes = find_and_joins(event_indexes, succession_matrix, dependancy_matrix, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 'B', 'B': 'D'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events, logs = process_logs(\"TDlog.csv\")\n",
    "def loops(events, logs):\n",
    "    loops_finded = {}\n",
    "    for log in logs.values():\n",
    "        appearances = defaultdict(int)\n",
    "        for event_index in range(len(log)):\n",
    "            event = log[event_index]\n",
    "            appearances[event] += 1\n",
    "            if appearances[event] > 1:\n",
    "                loops_finded[log[event_index-1]] = log[event_index]\n",
    "    return loops_finded\n",
    "\n",
    "loops(events, logs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
